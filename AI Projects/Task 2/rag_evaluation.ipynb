{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90dc458a",
   "metadata": {},
   "source": [
    "# AI Assignment from Vijayi WFH Technologies Pvt Ltd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5909d698",
   "metadata": {},
   "source": [
    "## Task 2 - RAG evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6998ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ./rag_pipeline.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d153790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"  # Replace with your actual key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f451f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", api_key=\"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\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d41809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_queries = [ \n",
    "    \"Quotes about insanity attributed to Einstein\",\n",
    "    \"Motivational quotes tagged ‘accomplishment\",\n",
    "    \"All Oscar Wilde quotes with humor\",\n",
    "    \"Quotes tagged with both ‘life’ and ‘love’ by 20thcentury authors\",\n",
    "    \"Quotes about humor and human nature\"\n",
    "]\n",
    "expected_responses = [\n",
    "    \"“Insanity is doing the same thing, over and over again, but expecting different results.” — Narcotics Anonymous \\n“There's a fine line between genius and insanity. I have erased this line.” — Oscar Levant \\n“I became insane, with long intervals of horrible sanity.” — Edgar Allan Poe \",\n",
    "    \"“To be yourself in a world that is constantly trying to make you something else is the greatest accomplishment.” — Ralph Waldo Emerson \\n“The starting point of all achievement is DESIRE. Keep this constantly in mind. Weak desire brings weak results, just as a small fire makes a small amount of heat.” — Napoleon Hill \\n“Success is not how high you have climbed, but how you make a positive difference to the world.” — Roy T. Bennett \",\n",
    "    \"“I am so clever that sometimes i dont understand a single word of what i am saying.” — Oscar Wilde \\n“Some cause happiness wherever they go others whenever they go.” — Oscar Wilde \\n“Always forgive your enemies; nothing annoys them so much.” — Oscar Wilde \",\n",
    "    \"“Love the life you live.live the life you love.” — Bob Marley \\n“Where there is love there is life.” — Mahatma Gandhi \\n“To lose balance sometimes for love is part of living a balancedlife.” — Elizabeth Gilbert \",\n",
    "    \"“I love mankind ... it's people I can't stand!!” — Charles M. Schulz \\n“Where is human nature so weak as in the bookstore?” — Henry Ward Beecherr \\n“There is nothing in the world so irresistibly contagious as laughter and good humor.” — Charles Dickens \"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2155e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "for query,reference in zip(sample_queries,expected_responses):\n",
    "\n",
    "    relevant_docs = expected_responses\n",
    "    answer = rag_pipeline(query)\n",
    "    response = \"\"\n",
    "    for i in range(0,3):\n",
    "        response += f\"{answer['source_quotes'][i]['quote']} — {answer['source_quotes'][i]['author'].rstrip(',')} \\n\"\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\":query,\n",
    "            \"retrieved_contexts\":relevant_docs,\n",
    "            \"response\":response,\n",
    "            \"reference\":reference\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d40987f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    ContextRecall,\n",
    "    ContextPrecision,\n",
    "    AnswerCorrectness\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3522f3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1fcb0f9161426285f883d938342240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[2]: RateLimitError(Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}})\n",
      "Exception raised in Job[1]: RateLimitError(Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}})\n",
      "Exception raised in Job[0]: TimeoutError()\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert your dataset to RAGAS format\n",
    "ragas_dataset = []\n",
    "for item in dataset:\n",
    "    ragas_dataset.append({\n",
    "        \"question\": item[\"user_input\"],\n",
    "        \"answer\": item[\"response\"].rstrip('\\n'),\n",
    "        \"contexts\": item[\"retrieved_contexts\"],\n",
    "        \"ground_truth\": item[\"reference\"].rstrip('\\n')\n",
    "    })\n",
    "\n",
    "# Create Evaluation Dataset\n",
    "evaluation_dataset = Dataset.from_list(ragas_dataset)\n",
    "\n",
    "# Define metrics\n",
    "metrics = [\n",
    "    ContextRecall(),\n",
    "    ContextPrecision(),\n",
    "    AnswerCorrectness()\n",
    "]\n",
    "\n",
    "# Run evaluation with error handling\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=evaluation_dataset,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c38b677b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_recall': 1, 'context_precision': 1, 'answer_correctness': 1}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
